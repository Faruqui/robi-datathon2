{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0a5c8b",
   "metadata": {},
   "source": [
    "# Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b36f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0172568a",
   "metadata": {},
   "source": [
    "# Import External Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7d2e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8bf130",
   "metadata": {},
   "source": [
    "# Data Manipulation Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab2363b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(directory):\n",
    "    df = pd.read_csv(filepath_or_buffer=directory)\n",
    "    return df\n",
    "\n",
    "def prop_split_df(df, props, seed):\n",
    "    random.seed(seed)\n",
    "    df = df.copy(deep=True)\n",
    "    indices = list(range(0,df.shape[0],1))\n",
    "    index_sets = list()\n",
    "    for iterator, prop in enumerate(props):\n",
    "        if iterator+1 == len(props):\n",
    "            index_sets.append(\n",
    "                indices if int(round(prop*df.shape[0])) > len(indices)\n",
    "                else set(random.sample(indices, int(round(prop*df.shape[0]))))\n",
    "            )\n",
    "            pass\n",
    "        else:\n",
    "            index_sets.append(\n",
    "                set(random.sample(indices, int(round(prop*df.shape[0]))))\n",
    "            )\n",
    "            indices = list(set(indices) - index_sets[-1])\n",
    "            pass\n",
    "        pass\n",
    "    dfs = list()\n",
    "    for index_set in index_sets:\n",
    "        dfs.append(\n",
    "            df[\n",
    "                df.index.isin(index_set)\n",
    "            ].sample(\n",
    "                frac=1,\n",
    "                replace=False,\n",
    "                random_state=seed,\n",
    "                ignore_index=True\n",
    "            ).reset_index(drop=True)\n",
    "        )\n",
    "        pass\n",
    "    return dfs\n",
    "\n",
    "def stratified_split(df, col, props, seed):\n",
    "    df = df.copy(deep=True)\n",
    "    col_values = list(set(df[col].values))\n",
    "    dfs = list()\n",
    "    for col_value in col_values:\n",
    "        dfs.append(\n",
    "            prop_split_df(\n",
    "                df = df[df[col]==col_value].reset_index(drop=True),\n",
    "                props = props,\n",
    "                seed = seed\n",
    "            )\n",
    "        )\n",
    "        pass\n",
    "    dfs = np.array(dfs, dtype=object).T.tolist()\n",
    "    dfs = [\n",
    "        pd.concat(\n",
    "            [df.astype(object) for df in df_tuple],\n",
    "            axis=0\n",
    "        ).reset_index(drop=True)\n",
    "        for df_tuple in dfs\n",
    "    ]\n",
    "    return dfs\n",
    "\n",
    "def oversampled_split(df, col, props, seed, algorithm, sampling_strategy, k_neighbors=5, m_neighbors=10):\n",
    "    df = df.copy(deep=True)\n",
    "    if algorithm.upper()==\"SMOTE\":\n",
    "        smote_algorithm = SMOTE(sampling_strategy=sampling_strategy, random_state=seed, k_neighbors=k_neighbors, n_jobs=-1)\n",
    "        pass\n",
    "    elif algorithm.upper()==\"BORDERLINESMOTE\":\n",
    "        smote_algorithm = BorderlineSMOTE(sampling_strategy=sampling_strategy, random_state=seed, k_neighbors=k_neighbors, n_jobs=-1, m_neighbors=m_neighbors)\n",
    "        pass\n",
    "    elif algorithm.upper()==\"SVMSMOTE\":\n",
    "        smote_algorithm = SVMSMOTE(sampling_strategy=sampling_strategy, random_state=seed, k_neighbors=k_neighbors, n_jobs=-1, m_neighbors=m_neighbors)\n",
    "        pass\n",
    "    resampled_features, resampled_targets = smote_algorithm.fit_resample(df.drop([col], axis=1), df[col])\n",
    "    df = pd.concat([resampled_features, resampled_targets], axis=1).reset_index(drop=True)\n",
    "    dfs = prop_split_df(df, props, seed)\n",
    "    return dfs\n",
    "\n",
    "def undersampled_split(df, col, props, seed):\n",
    "    df = df.copy(deep=True)\n",
    "    value_counts = df.groupby(col).count().to_dict()\n",
    "    value_counts = {key:min(value.values()) for key,value in value_counts.items()}\n",
    "    critical_value = max(value_counts.values())\n",
    "    global_prop = min([sum(props), 1.0])\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df[\n",
    "                df[col] == col_value\n",
    "            ].sample(\n",
    "                int(round(global_prop*critical_value)),\n",
    "                replace=False,\n",
    "                random_state=seed,\n",
    "                ignore_index=True\n",
    "            ) for col_value in set(df[col].values)\n",
    "        ],\n",
    "        axis=0\n",
    "    ).reset_index(drop=True)\n",
    "    dfs = prop_split_df(df, props, seed)\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41698e20",
   "metadata": {},
   "source": [
    "# Preprocessor Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d40df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_ohe(df, cols):\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    for col in cols:\n",
    "        encoder = OneHotEncoder(categories=\"auto\", dtype=int)\n",
    "        original_cols = list(df.columns)\n",
    "        encoded_vals = encoder.fit_transform(df[[col]]).toarray().T\n",
    "        encoded_cols = list(encoder.get_feature_names_out())\n",
    "        index = original_cols.index(col)\n",
    "        new_cols = original_cols[:index] + encoded_cols + original_cols[index+1:]\n",
    "        for iterator, encoded_col in enumerate(encoded_cols):\n",
    "            df[encoded_col] = encoded_vals[iterator]\n",
    "            pass\n",
    "        df = df[new_cols]\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "def decoder_ohe(df, cols):\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    def arg_max(arr):\n",
    "        arr = list(arr)\n",
    "        return arr.index(1)\n",
    "    \n",
    "    for col in cols:\n",
    "        original_cols = list(df.columns)\n",
    "        encoded_cols = [original_col for original_col in original_cols if original_col.startswith(col)]\n",
    "        encoded_vals = df[encoded_cols].values\n",
    "        decoded_vals = [\"_\".join(encoded_col.split(\"_\")[1:]) for encoded_col in encoded_cols]\n",
    "        first_index = original_cols.index(col+\"_\"+decoded_vals[0])\n",
    "        last_index = original_cols.index(col+\"_\"+decoded_vals[-1])\n",
    "        new_cols = original_cols[:first_index] + [col] + original_cols[last_index+1:]\n",
    "        encoded_vals = np.apply_along_axis(arg_max, 1, encoded_vals)\n",
    "        df[col] = encoded_vals\n",
    "        df[col] = df[col].apply(lambda arg : decoded_vals[arg])\n",
    "        df = df[new_cols]\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "def encoder_ord(df, cols):\n",
    "    df = df.copy(deep=True)\n",
    "    mapper = dict()\n",
    "    \n",
    "    for col in cols:\n",
    "        encoder = OrdinalEncoder(categories=\"auto\", dtype=int)\n",
    "        encoded_vals = encoder.fit_transform(df[[col]])\n",
    "        df[col] = encoded_vals\n",
    "        original_vals = list(encoder.categories_[0])\n",
    "        mapper[col] = original_vals\n",
    "        pass\n",
    "    return df, mapper\n",
    "\n",
    "def decoder_ord(df, cols, mapper):\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    for col in cols:\n",
    "        df[col] = df[col].apply(lambda arg : mapper[col][arg])\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4edb4",
   "metadata": {},
   "source": [
    "# Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4b9cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_SEED = 1995\n",
    "PARAM_TRAIN_DATA_DIR = \"./data/train.csv\"\n",
    "PARAM_VALIDATION_DATA_DIR = \"./data/bible_test.csv\"\n",
    "PARAM_TEST_DATA_DIR = \"./data/test.csv\"\n",
    "PARAM_OHE_COLS = [\"n12\", \"n13\", \"gender\", \"s48\", \"s53\", \"s58\", \"s69\", \"s11\", \"s12\", \"s13\", \"s16\", \"s17\", \"s18\", \"s52\", \"s70\", \"s71\", \"n15\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e1d82",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "644d2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data_loader(PARAM_TRAIN_DATA_DIR)\n",
    "df_train = df_train.drop([\"s54\", \"s55\", \"s56\", \"s57\", \"s59\", \"id\"], axis=1)\n",
    "df_train = encoder_ohe(df_train, PARAM_OHE_COLS)\n",
    "df_train = oversampled_split(\n",
    "                                df=df_train, \n",
    "                                col='label', \n",
    "                                props=[1], \n",
    "                                seed=PARAM_SEED, \n",
    "                                algorithm='SVMSMOTE', \n",
    "                                sampling_strategy='minority', \n",
    "                                k_neighbors=5, \n",
    "                                m_neighbors=10\n",
    "                            )\n",
    "\n",
    "df_val = data_loader(PARAM_VALIDATION_DATA_DIR)\n",
    "df_val = df_val.drop([\"s54\", \"s55\", \"s56\", \"s57\", \"s59\", \"id\"], axis=1)\n",
    "df_val = encoder_ohe(df_val, PARAM_OHE_COLS)\n",
    "\n",
    "df_test = data_loader(PARAM_TEST_DATA_DIR)\n",
    "comp_ids = list(df_test['id'])\n",
    "df_test = df_test.drop([\"s54\", \"s55\", \"s56\", \"s57\", \"s59\", \"id\"], axis=1)\n",
    "df_test = encoder_ohe(df_test, PARAM_OHE_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab06e543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train[0].drop(['label'], axis=1)\n",
    "X_test = df_val.drop(['label'], axis=1)\n",
    "\n",
    "y_train = df_train[0]['label']\n",
    "y_test = df_val['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd4a87",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8626703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf1 = RandomForestClassifier(random_state=PARAM_SEED, n_estimators=300)\n",
    "clf2 = XGBClassifier(learning_rate=0.01, n_estimators=1500,\n",
    "                       max_depth=5, min_child_weight=0,\n",
    "                       gamma=0, subsample=0.7,\n",
    "                       colsample_bytree=0.7, nthread=-1,\n",
    "                       reg_alpha=0.00006, random_state=PARAM_SEED)\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2], voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27e58947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross Validation. Ignore for future training\n",
    "\n",
    "# for clf, label in zip([clf1, clf2, eclf], \n",
    "#                       ['Random Forest', \n",
    "#                        'XGBoost', \n",
    "#                        'EnsembleVoteClassifier']):\n",
    "\n",
    "#     scores = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "#     print(\"ROC_AUC: %0.2f [%s]\" % (scores.mean(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bde72f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 196 ms, total: 3min 21s\n",
      "Wall time: 52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eclf_fit = eclf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e433113",
   "metadata": {},
   "source": [
    "### Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1d666cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = eclf_fit.predict_proba(X_test.values)[:,1]\n",
    "y_score = [1 if value>=0.25 else 0 for value in list(y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2773eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC score: 0.9431239388794568\n",
      "[[4176  536]\n",
      " [   0  952]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      4712\n",
      "           1       0.64      1.00      0.78       952\n",
      "\n",
      "    accuracy                           0.91      5664\n",
      "   macro avg       0.82      0.94      0.86      5664\n",
      "weighted avg       0.94      0.91      0.91      5664\n",
      "\n",
      "0.9431239388794568\n"
     ]
    }
   ],
   "source": [
    "print('ROCAUC score:', roc_auc_score(y_test, y_score))\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_score))\n",
    "print(roc_auc_score(y_test, y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea018271",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df_test.columns if col != 'id']\n",
    "y_pred_comp = eclf_fit.predict_proba(df_test[features].values)[:,1]\n",
    "y_score_comp = [1 if value>=0.25 else 0 for value in list(y_comp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03cd1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dict = {\"id\": comp_ids, \"label\": y_score_comp}\n",
    "submission_df = pd.DataFrame(comp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3474a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'gAAAAABinOi328DZcweGB4_nOyHA3Dy6o1YKYKyf3COx...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'gAAAAABinOikutEIBjkUXl9lYTg4RI6jc4NfiMUCcVsn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'gAAAAABinOjBM70jBXOroAlUSq5lNXMd_oP0PU7jLQE5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'gAAAAABinOimitAnqlgOcqnD_LeNL3WEbXNGvjd3QVPi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'gAAAAABinOi3W9p3Oka5MV_dc2TeorZUcIWOnnODSx7E...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85060</th>\n",
       "      <td>b'gAAAAABinOjbnJVk2-nOVQsYB9p4DK26fTLLik_UR2H0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85061</th>\n",
       "      <td>b'gAAAAABinOi7ixyXrlKYlx8D9i0-TIPD5elP2k-vuekn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85062</th>\n",
       "      <td>b'gAAAAABinOi31zWSlD0OMhbBd3_weh7Kq6aPeO4yYqns...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85063</th>\n",
       "      <td>b'gAAAAABinOjIe7jFVk9k7jiH8Y3rdpUHDTZG2T2isunp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85064</th>\n",
       "      <td>b'gAAAAABinOiiLo4KNZVgClHgtOFRzEU9O97My6MowJFa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id  label\n",
       "0      b'gAAAAABinOi328DZcweGB4_nOyHA3Dy6o1YKYKyf3COx...      1\n",
       "1      b'gAAAAABinOikutEIBjkUXl9lYTg4RI6jc4NfiMUCcVsn...      1\n",
       "2      b'gAAAAABinOjBM70jBXOroAlUSq5lNXMd_oP0PU7jLQE5...      1\n",
       "3      b'gAAAAABinOimitAnqlgOcqnD_LeNL3WEbXNGvjd3QVPi...      0\n",
       "4      b'gAAAAABinOi3W9p3Oka5MV_dc2TeorZUcIWOnnODSx7E...      0\n",
       "...                                                  ...    ...\n",
       "85060  b'gAAAAABinOjbnJVk2-nOVQsYB9p4DK26fTLLik_UR2H0...      1\n",
       "85061  b'gAAAAABinOi7ixyXrlKYlx8D9i0-TIPD5elP2k-vuekn...      1\n",
       "85062  b'gAAAAABinOi31zWSlD0OMhbBd3_weh7Kq6aPeO4yYqns...      1\n",
       "85063  b'gAAAAABinOjIe7jFVk9k7jiH8Y3rdpUHDTZG2T2isunp...      1\n",
       "85064  b'gAAAAABinOiiLo4KNZVgClHgtOFRzEU9O97My6MowJFa...      1\n",
       "\n",
       "[85065 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f94d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df.to_csv(\"eclf_v4_svmsmoat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42285f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
