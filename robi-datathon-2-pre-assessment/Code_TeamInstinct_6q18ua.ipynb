{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0a5c8b",
   "metadata": {},
   "source": [
    "# Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b36f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0172568a",
   "metadata": {},
   "source": [
    "# Import External Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d2e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8bf130",
   "metadata": {},
   "source": [
    "# Data Manipulation Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab2363b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>s11</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s48</th>\n",
       "      <th>s52</th>\n",
       "      <th>...</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>n9</th>\n",
       "      <th>n10</th>\n",
       "      <th>n11</th>\n",
       "      <th>n12</th>\n",
       "      <th>n13</th>\n",
       "      <th>n14</th>\n",
       "      <th>n15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>...</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>...</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "      <td>3808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  gender   s11   s12   s13   s16   s17   s18   s48   s52  ...  \\\n",
       "label                                                                ...   \n",
       "0      3808    3808  3808  3808  3808  3808  3808  3808  3808  3808  ...   \n",
       "1      3808    3808  3808  3808  3808  3808  3808  3808  3808  3808  ...   \n",
       "\n",
       "         n6    n7    n8    n9   n10   n11   n12   n13   n14   n15  \n",
       "label                                                              \n",
       "0      3808  3808  3808  3808  3808  3808  3808  3808  3808  3808  \n",
       "1      3808  3808  3808  3808  3808  3808  3808  3808  3808  3808  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_loader(directory):\n",
    "    df = pd.read_csv(filepath_or_buffer=directory)\n",
    "    return df\n",
    "\n",
    "def prop_split_df(df, props, seed):\n",
    "    random.seed(seed)\n",
    "    df = df.copy(deep=True)\n",
    "    indices = list(range(0,df.shape[0],1))\n",
    "    index_sets = list()\n",
    "    for iterator, prop in enumerate(props):\n",
    "        if iterator+1 == len(props):\n",
    "            index_sets.append(\n",
    "                indices if int(round(prop*df.shape[0])) > len(indices)\n",
    "                else set(random.sample(indices, int(round(prop*df.shape[0]))))\n",
    "            )\n",
    "            pass\n",
    "        else:\n",
    "            index_sets.append(\n",
    "                set(random.sample(indices, int(round(prop*df.shape[0]))))\n",
    "            )\n",
    "            indices = list(set(indices) - index_sets[-1])\n",
    "            pass\n",
    "        pass\n",
    "    dfs = list()\n",
    "    for index_set in index_sets:\n",
    "        dfs.append(\n",
    "            df[\n",
    "                df.index.isin(index_set)\n",
    "            ].sample(\n",
    "                frac=1,\n",
    "                replace=False,\n",
    "                random_state=seed,\n",
    "                ignore_index=True\n",
    "            ).reset_index(drop=True)\n",
    "        )\n",
    "        pass\n",
    "    return dfs\n",
    "\n",
    "def stratified_split(df, col, props, seed):\n",
    "    df = df.copy(deep=True)\n",
    "    col_values = list(set(df[col].values))\n",
    "    dfs = list()\n",
    "    for col_value in col_values:\n",
    "        dfs.append(\n",
    "            prop_split_df(\n",
    "                df = df[df[col]==col_value].reset_index(drop=True),\n",
    "                props = props,\n",
    "                seed = seed\n",
    "            )\n",
    "        )\n",
    "        pass\n",
    "    dfs = np.array(dfs, dtype=object).T.tolist()\n",
    "    dfs = [\n",
    "        pd.concat(\n",
    "            [df.astype(object) for df in df_tuple],\n",
    "            axis=0\n",
    "        ).reset_index(drop=True)\n",
    "        for df_tuple in dfs\n",
    "    ]\n",
    "    return dfs\n",
    "\n",
    "def oversampled_split(df, col, props, seed, algorithm, sampling_strategy, k_neighbors=5, m_neighbors=10):\n",
    "    df = df.copy(deep=True)\n",
    "    if algorithm.upper()==\"SMOTE\":\n",
    "        smote_algorithm = SMOTE(sampling_strategy=sampling_strategy, random_state=seed, k_neighbors=k_neighbors, n_jobs=-1)\n",
    "        pass\n",
    "    elif algorithm.upper()==\"BORDERLINESMOTE\":\n",
    "        smote_algorithm = BorderlineSMOTE(sampling_strategy=sampling_strategy, random_state=seed, k_neighbors=k_neighbors, n_jobs=-1, m_neighbors=m_neighbors)\n",
    "        pass\n",
    "    elif algorithm.upper()==\"SVMSMOTE\":\n",
    "        smote_algorithm = SVMSMOTE(sampling_strategy=sampling_strategy, random_state=seed, k_neighbors=k_neighbors, n_jobs=-1, m_neighbors=m_neighbors)\n",
    "        pass\n",
    "    resampled_features, resampled_targets = smote_algorithm.fit_resample(df.drop([col], axis=1), df[col])\n",
    "    df = pd.concat([resampled_features, resampled_targets], axis=1).reset_index(drop=True)\n",
    "    dfs = prop_split_df(df, props, seed)\n",
    "    return dfs\n",
    "\n",
    "def undersampled_split(df, col, props, seed):\n",
    "    df = df.copy(deep=True)\n",
    "    value_counts = df.groupby(col).count().to_dict()\n",
    "    value_counts = {key:min(value.values()) for key,value in value_counts.items()}\n",
    "    critical_value = max(value_counts.values())\n",
    "    global_prop = min([sum(props), 1.0])\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df[\n",
    "                df[col] == col_value\n",
    "            ].sample(\n",
    "                int(round(global_prop*critical_value)),\n",
    "                replace=False,\n",
    "                random_state=seed,\n",
    "                ignore_index=True\n",
    "            ) for col_value in set(df[col].values)\n",
    "        ],\n",
    "        axis=0\n",
    "    ).reset_index(drop=True)\n",
    "    dfs = prop_split_df(df, props, seed)\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41698e20",
   "metadata": {},
   "source": [
    "# Preprocessor Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_ohe(df, cols):\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    for col in cols:\n",
    "        encoder = OneHotEncoder(categories=\"auto\", dtype=int)\n",
    "        original_cols = list(df.columns)\n",
    "        encoded_vals = encoder.fit_transform(df[[col]]).toarray().T\n",
    "        encoded_cols = list(encoder.get_feature_names_out())\n",
    "        index = original_cols.index(col)\n",
    "        new_cols = original_cols[:index] + encoded_cols + original_cols[index+1:]\n",
    "        for iterator, encoded_col in enumerate(encoded_cols):\n",
    "            df[encoded_col] = encoded_vals[iterator]\n",
    "            pass\n",
    "        df = df[new_cols]\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "def decoder_ohe(df, cols):\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    def arg_max(arr):\n",
    "        arr = list(arr)\n",
    "        return arr.index(1)\n",
    "    \n",
    "    for col in cols:\n",
    "        original_cols = list(df.columns)\n",
    "        encoded_cols = [original_col for original_col in original_cols if original_col.startswith(col)]\n",
    "        encoded_vals = df[encoded_cols].values\n",
    "        decoded_vals = [\"_\".join(encoded_col.split(\"_\")[1:]) for encoded_col in encoded_cols]\n",
    "        first_index = original_cols.index(col+\"_\"+decoded_vals[0])\n",
    "        last_index = original_cols.index(col+\"_\"+decoded_vals[-1])\n",
    "        new_cols = original_cols[:first_index] + [col] + original_cols[last_index+1:]\n",
    "        encoded_vals = np.apply_along_axis(arg_max, 1, encoded_vals)\n",
    "        df[col] = encoded_vals\n",
    "        df[col] = df[col].apply(lambda arg : decoded_vals[arg])\n",
    "        df = df[new_cols]\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "def encoder_ord(df, cols):\n",
    "    df = df.copy(deep=True)\n",
    "    mapper = dict()\n",
    "    \n",
    "    for col in cols:\n",
    "        encoder = OrdinalEncoder(categories=\"auto\", dtype=int)\n",
    "        encoded_vals = encoder.fit_transform(df[[col]])\n",
    "        df[col] = encoded_vals\n",
    "        original_vals = list(encoder.categories_[0])\n",
    "        mapper[col] = original_vals\n",
    "        pass\n",
    "    return df, mapper\n",
    "\n",
    "def decoder_ord(df, cols, mapper):\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    for col in cols:\n",
    "        df[col] = df[col].apply(lambda arg : mapper[col][arg])\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab016d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408bd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
